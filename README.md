Inspired by [micrograd](https://github.com/karpathy/micrograd), this program builds a simple neural network from scratch, without relying on deep learning libraries like PyTorch or TensorFlow. It includes a backpropagation algorithm to compute the gradient of any intermediate value within the network, allowing for efficient optimization. Additionally, you can visualize the structure of the network using the draw_dot(value_object) function, adapted from the original notebook, which renders a clear, graphical representation of each computation node and connection in the network.
